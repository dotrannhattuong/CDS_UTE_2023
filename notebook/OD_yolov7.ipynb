{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2bV2OSVjV78o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69044bf7-d970-4631-b3d9-74e2ebc51a3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "gr5fp9HH0e4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Clone yolov7 \n"
      ],
      "metadata": {
        "id": "NuDm2VbIaVrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone source code YOLOv7 về thư mục OD_train   \n",
        "%cd /content/drive/MyDrive/OD_train\n",
        "!git clone https://github.com/augmentedstartups/yolov7.git"
      ],
      "metadata": {
        "id": "vj9nUcDuYQWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Download required packages"
      ],
      "metadata": {
        "id": "kMYQ_2R-b2cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cài đặt các thư viện cần thiết để train YOLOv7\n",
        "%cd /content/drive/MyDrive/OD_train/yolov7\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Tl7A5JqWYY8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Download pretrained model"
      ],
      "metadata": {
        "id": "hbhlbfqgb-3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải weight pretrain \n",
        "%cd /content/drive/MyDrive/OD_train/yolov7\n",
        "!mkdir pretrain\n",
        "%cd pretrain\n",
        "!rm yolov7.pt\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "id": "THEnOKuScFhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Prepare dataset"
      ],
      "metadata": {
        "id": "5JIOWugXfZz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone soucre Data"
      ],
      "metadata": {
        "id": "O-c_AvZcitTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone source Data về thư mục OD_train   \n",
        "%cd /content/drive/MyDrive/OD_train\n",
        "!git clone https://github.com/dotrannhattuong/Dataset_OD_SelfDrivingCar"
      ],
      "metadata": {
        "id": "mPASyZcSYUhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check data"
      ],
      "metadata": {
        "id": "wlp4mP_r3Gxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "txt_files_glob = glob.glob('/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/yolo_data_detect/*/*/*.txt')\n",
        "images_files_glob = glob.glob('/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/yolo_data_detect/*/*images/*')\n",
        "len(txt_files_glob), len(images_files_glob)"
      ],
      "metadata": {
        "id": "1Qu--P9sNQWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4cf9d9-9da4-4f43-99c9-22e5d0685b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7568, 7568)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split to train/val/test folder"
      ],
      "metadata": {
        "id": "rcsyRKo6d59r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "from shutil import copyfile"
      ],
      "metadata": {
        "id": "dKxX2xMp3MC3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "txt_files_glob = glob.glob('/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/yolo_data_detect/*/*/*.txt')\n",
        "\n",
        "for txt in txt_files_glob:\n",
        "  img_name = txt.split('/')[-1]\n",
        "  img_name = img_name.split('.')\n",
        "  img_name = '.'.join(img_name[:-1])\n",
        "  copyfile(txt, os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new_noSplit\", img_name + '.txt'))\n"
      ],
      "metadata": {
        "id": "M5D1D3-Bop3O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Dataset\n",
        "dataset_labels_path = '/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/yolo_data_detect'\n",
        "\n",
        "image_list = glob.glob(f'{dataset_labels_path}/*/*images/*')\n",
        "train_test_list, val_list = train_test_split(image_list, test_size=0.2, random_state=42)\n",
        "train_list, test_list = train_test_split(train_test_list, test_size=0.125, random_state=42)\n",
        "\n",
        "print('total =',len(image_list))\n",
        "print('train :',len(train_list))\n",
        "print('val  :',len(val_list))\n",
        "print('test  :',len(test_list))"
      ],
      "metadata": {
        "id": "Fy9-bA4ReFQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760dd0b5-985d-4215-ed7a-4da9b66a983d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total = 7568\n",
            "train : 5297\n",
            "val  : 1514\n",
            "test  : 757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # train split\n",
        "for filename in train_list:\n",
        "    img_name = filename.split('/')[-1]\n",
        "    img_name = img_name.split('.')\n",
        "    img_name = '.'.join(img_name[:-1])\n",
        "    copyfile(os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new_noSplit\", img_name + '.txt'), os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/train/labels\", img_name + '.txt'))\n",
        "    copyfile(filename, os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/train/images\", img_name + '.png'))\n",
        "\n",
        "  # val split\n",
        "for filename in val_list:\n",
        "    img_name = filename.split('/')[-1]\n",
        "    img_name = img_name.split('.')\n",
        "    img_name = '.'.join(img_name[:-1])\n",
        "    copyfile(os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new_noSplit\", img_name + '.txt'), os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/val/labels\", img_name + '.txt'))\n",
        "    copyfile(filename, os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/val/images\", img_name + '.png'))\n",
        "\n",
        "  # test split\n",
        "for filename in test_list:\n",
        "    img_name = filename.split('/')[-1]\n",
        "    img_name = img_name.split('.')\n",
        "    img_name = '.'.join(img_name[:-1])\n",
        "    copyfile(os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new_noSplit\", img_name + '.txt'), os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/test/labels\", img_name + '.txt'))\n",
        "    copyfile(filename, os.path.join(\"/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/test/images\", img_name + '.png'))"
      ],
      "metadata": {
        "id": "PY5-0Q1ChjZy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Data"
      ],
      "metadata": {
        "id": "5knwhSOEf80F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import os\n",
        "from shutil import copyfile"
      ],
      "metadata": {
        "id": "TVhWTRZUgeha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uKG7T3Sqf6l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "for file in glob.glob('/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/yolo_data_detect/*/*/*.txt'):\n",
        "  df = pd.read_csv(file, sep=\" \", header=None, names=['class', 'x', 'y', 'w', 'h'])\n",
        "  lst.append(df)\n",
        "signs = pd.concat(lst)\n",
        "print(signs)"
      ],
      "metadata": {
        "id": "WMwX4XiTgTkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "data['counts'] = signs['class'].value_counts()\n",
        "data.index = ['turn_right', 'straight', 'no_turn_left', 'no_turn_right', 'no_straight', 'car', 'unknown', 'turn_left']\n",
        "data['title'] = data.index\n",
        "print(data)"
      ],
      "metadata": {
        "id": "WOOEvzI_jNyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(data).mark_bar().encode(\n",
        "    x=alt.X('counts', axis=alt.Axis(title='Counts')),\n",
        "    y=alt.Y('title',\n",
        "        sort=alt.EncodingSortField(field='counts', order='ascending', op='sum'),\n",
        "        axis=alt.Axis(title='Title')\n",
        "    ),\n",
        "    color=alt.Color('title:N')\n",
        ")"
      ],
      "metadata": {
        "id": "AQ1d6zl4gCLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Prepare custom .yaml file\n"
      ],
      "metadata": {
        "id": "cENXR4B9ceXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo 1 file yaml để YOLOv7 biết:\n",
        "# - Đường dẫn đến thư mục train, test (nếu có, nếu không thì dùng luôn đường dẫn đến train)\n",
        "# - Số lượng class qua biến nc (number of class)\n",
        "# - Tên của các class\n",
        "%cd /content/drive/MyDrive/OD_train/yolov7\n",
        "!rm data/mydataset.yaml # nếu có\n",
        "!echo 'train: /content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/train' >> data/mydataset.yaml\n",
        "!echo 'val: /content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/val' >> data/mydataset.yaml\n",
        "!echo 'nc: 9' >> data/mydataset.yaml\n",
        "!echo \"names: ['no', 'turn_right', 'straight', 'no_turn_left', 'no_turn_right', 'no_straight', 'car', 'unknown', 'turn_left']\" >> data/mydataset.yaml"
      ],
      "metadata": {
        "id": "2C3zTAz_Yeby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train"
      ],
      "metadata": {
        "id": "HwdzsfvxdSzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Training"
      ],
      "metadata": {
        "id": "TIKyoPgedrlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model YOLOv7 với dữ liệu OD\n",
        "%cd /content/drive/MyDrive/OD_train/yolov7\n",
        "!python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 300 --data data/mydataset.yaml --weights 'pretrain/yolov7.pt' --hyp data/hyp.scratch.p5.yaml"
      ],
      "metadata": {
        "id": "TnW0eYbvYfl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b33380e-16eb-461a-af83-2184597703e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OD_train/yolov7\n",
            "YOLOR 🚀 v0.1-104-g941b94c torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/mydataset.yaml', device='', entity=None, epochs=300, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='pretrain/yolov7.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     77308  models.yolo.IDetect                     [9, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37239708 parameters, 37239708 gradients, 105.3 GFLOPS\n",
            "\n",
            "Transferred 552/566 items from pretrain/yolov7.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/OD_train/Dataset_OD_SelfDrivingCar/data_new/train/labels' images and labels... 688 found, 0 missing, 0 empty, 0 corrupted:  13% 688/5179 [10:17<54:53,  1.36it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resume "
      ],
      "metadata": {
        "id": "jMkGwfg6d4WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CD_train/yolov7\n",
        "\n",
        "!python train.py --resume /content/drive/MyDrive/UTE2023/train/exp/weights/last.pt --cache"
      ],
      "metadata": {
        "id": "U7Ae-847eC0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Inference"
      ],
      "metadata": {
        "id": "2vRyd52mejgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Nhận diện thử với weights vừa train\n",
        "%cd /content/drive/MyDrive/OD_train/yolov7\n",
        "!python detect.py --weights /content/drive/MyDrive/OD_train/exp2/weights/best.pt --source /content/drive/MyDrive/OD_train/test"
      ],
      "metadata": {
        "id": "iHAOgbuwSAUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem ảnh đã nhận diện\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"/content/drive/MyDrive/OD_train/yolov7/runs/detect/exp\"))"
      ],
      "metadata": {
        "id": "Tc97HVbOfGWg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}